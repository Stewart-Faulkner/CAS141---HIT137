import nltk  
from nltk.corpus import stopwords  
from collections import Counter  
import pandas as pd  

nltk.data.path.append('C:\\Users\\CJJ255\\AppData\\Roaming\\nltk_data') 

# Read the file content
text_file_path = 'D:/project1/continue/test1/output/output.txt'  
with open(text_file_path, 'r', encoding='utf-8') as file:  
    text = file.read()  

# Tokenize and convert to lowercase
words = nltk.word_tokenize(text.lower())  

# Get the list of English stopwords
stop_words = set(stopwords.words('english'))  

# Remove stopwords and non-alphabetical characters
filtered_words = [word for word in words if word.isalpha() and word not in stop_words]  

# Count the word frequencies
word_counts = Counter(filtered_words)  

# Get the top 30 most common words
most_common_words = word_counts.most_common(30)  

# Save the result to a DataFrame
df = pd.DataFrame(most_common_words, columns=['Word', 'Frequency'])  

# Export the DataFrame to an Excel file
output_excel_path = 'D:/project1/continue/test1/output/Top_30_Words.xlsx'  
df.to_excel(output_excel_path, index=False)  

print(f"Top 30 common words have been saved to {output_excel_path}")  
